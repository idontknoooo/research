{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import requests\n",
    "import string\n",
    "from xlutils.copy import copy\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import sys\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(i, career_href, letter):\n",
    "\n",
    "    wb = open('cv-'+str(letter)+'.csv', mode='a', encoding='utf-8', newline=\"\\n\")\n",
    "    headers = {\n",
    "        'User-Agent': \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\"}\n",
    "\n",
    "    # Request Personal Profile\n",
    "    start_html = requests.get(career_href, headers=headers)\n",
    "    # HTML code\n",
    "    Soup = BeautifulSoup(start_html.text, 'lxml')\n",
    "    # all_tr: All information for one person, long <tr>\n",
    "    all_tr = Soup.find_all('tr') \n",
    "    # number of all_tr\n",
    "    num_tr = len(all_tr)\n",
    "    # name is the last tr content\n",
    "    cur_name = all_tr[num_tr-1].get_text() # name without url\n",
    "    cur_name = cur_name.replace('\\n','')\n",
    "    index = 0\n",
    "    try:\n",
    "        for td in all_tr[0:num_tr-5]:\n",
    "            td_text = td.get_text()\n",
    "    \n",
    "            all_td = td.find_all('td') # all <td>s in <tr>\n",
    "            year = all_td[0].get_text().split(',')[0] # Year\n",
    "            year = year.replace('â€”', '-')\n",
    "            #print(all_td)\n",
    "            title = all_td[1].get_text().split(',')[0] # Title\n",
    "            # print(title)\n",
    "            for a in all_td[0:-1]:\n",
    "                    \n",
    "                #print(\"First: \" + first_td + \"\\n\")\n",
    "                more_a = a.find_all('a')\n",
    "                if more_a:\n",
    "                    info = title\n",
    "                    print(more_a)\n",
    "                    for content in more_a:\n",
    "                        info = info + ',' + content.get_text()\n",
    "                    info = info.replace('\\n','')\n",
    "                    \n",
    "\n",
    "                    result = cur_name + ',' + year + ',' + info + '\\n'\n",
    "\n",
    "                    wb.write(result)\n",
    "                    # wb.flush()\n",
    "                    index += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    wb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_string(s):\n",
    "    s1 = s.replace(\" \", \"%20\")\n",
    "    #s1 = s.replace(\"|\", \"%7C\")\n",
    "    #s1 = s.repalce(\"'\", \"%27\")\n",
    "    return s1\n",
    "\n",
    "def b(letter):\n",
    "\n",
    "    headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\"}\n",
    "    str_start = str(\"http://www.chinavitae.com/biography_browse.php?l=\")#+str(letter)\n",
    "\n",
    "    #range 0-26 represent a-z\n",
    "    for i in (range(0, 1)):    \n",
    "        # Search Url: http://www.chinavitae.com/biography_browse.php?l={A}\n",
    "        alpha_url = str_start + letter# + string.ascii_uppercase[i]\n",
    "        print(alpha_url)\n",
    "        # Get HTML requests\n",
    "        start_html = requests.get(alpha_url, headers=headers)\n",
    "        # Get HTML code from requests. Soup contains all HTML code\n",
    "        Soup = BeautifulSoup(start_html.text, 'lxml')\n",
    "        # <td> tags contain name list\n",
    "        all_td = Soup.find_all('td')\n",
    "        # Column 1,2,3,4 from name search page\n",
    "        for page in range(2, 6): # Loop from Col_1 to Col_4\n",
    "            # All names in one search page\n",
    "            cur_td = all_td[page]\n",
    "            # all_a: all names in a single row\n",
    "            all_a = cur_td.find_all('a')\n",
    "            # For each name in a row (4 in total)\n",
    "            for a in all_a: # Loop from Row_1 to Row_n\n",
    "                # Title: Zakir Shohrat. A name without \"_\"\n",
    "                title = a.get_text()\n",
    "                # A post address: /biography/Zakir_Shohrat\n",
    "                href = a['href']\n",
    "                # Fix invalid url: \" \"==%20 and |==%7C and '==%27\n",
    "                new_href = replace_string(href)\n",
    "                # Return full url for someone\n",
    "                career_href = \"http://www.chinavitae.com\" + new_href + \"/career\"\n",
    "                # extract the table content into excel. i: sheet number\n",
    "                extract(i, career_href, letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetcher(num, begin, end):\n",
    "\n",
    "    s = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    for i in range(begin, end):\n",
    "        b(s[i])\n",
    "        print(\"Fetcher: \" + str(num) + \", letter: \" + s[i] + \". Complete.\")\n",
    "    print(\"Fetcher: \" + str(num) + \" totally completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main complete\n",
      "http://www.chinavitae.com/biography_browse.php?l=A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"<ipython-input-4-ea82c0a2e6c4>\", line 5, in fetcher\n",
      "    b(s[i])\n",
      "  File \"<ipython-input-3-cb4fd6882c7b>\", line 40, in b\n",
      "    extract(i, career_href, letter)\n",
      "  File \"<ipython-input-2-5f0fd70f467c>\", line 3, in extract\n",
      "    wb = open('cv-'+str(letter)+'.csv', mode='a', encoding='utf-8', newline=\"\\n\")\n",
      "TypeError: file() takes at most 3 arguments (4 given)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = Thread(target=fetcher, args=('1', 0,6)) # ABCDEF\n",
    "# t2 = Thread(target=fetcher, args=('2', 6,12)) # GHIJKL\n",
    "# t3 = Thread(target=fetcher, args=('3', 12,18)) # MNOPQR\n",
    "# t4 = Thread(target=fetcher, args=('4', 18,23)) # STUVWXYZ \n",
    "# t5 = Thread(target=fetcher, args=('5', 23,26)) # MNO\n",
    "\n",
    "t1.start()\n",
    "# t2.start()\n",
    "# t3.start()\n",
    "# t4.start()\n",
    "# t5.start()\n",
    "\n",
    "print(\"Main complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
